---
title: "判别器增强"
pubDate: "2026-02-19 04:47:27"
---

### 判别器增强

NotebookLM 综合分析结果

  1. 根本原因
  ┌────────────────────┬─────────────────────────────────────────────────────────────────────────────────┐
    │        原因        │                                      解释                                       │
    ├────────────────────┼─────────────────────────────────────────────────────────────────────────────────┤
    │ Lipschitz 约束缺失 │ BatchNorm 无法约束判别器的 Lipschitz 常数，hinge loss 无界线性增长，logits 失控 │
    ├────────────────────┼─────────────────────────────────────────────────────────────────────────────────┤
    │ 梯度信号失衡       │ d_weight=500,000 说明 ∇L_adv 极其微小——D 虽然 logits 大，但梯度传递效率极低     │
    ├────────────────────┼─────────────────────────────────────────────────────────────────────────────────┤
    │ 学习率相同         │ G 和 D 用同一个 1e-5，D 跟不上 G 的分布变化                                     │
    └────────────────────┴─────────────────────────────────────────────────────────────────────────────────┘
  2. 增强判别器的方法（按优先级排序）
  优先级: 最高
    方法: Spectral Normalization 替换 BatchNorm
    要点: 约束每层谱范数，控制 Lipschitz 常数，防止 logits 爆炸。Hinge Loss 的标准搭配
    ────────────────────────────────────────
    优先级: 高
    方法: TTUR 不同学习率
    要点: D 的 lr 设为 G 的 2~4 倍（如 LR_D=4e-5, LR_G=1e-5），或增加 D 训练步数
    ────────────────────────────────────────
    优先级: 中
    方法: R1 Gradient Penalty
    要点: 在 D 的 loss 中增加 λ·E[‖∇D(x)‖²]，惩罚真实数据上的大梯度，将 logits 拉回合理范围
  3. 是否替换 Hinge Loss？

  暂不需要。 Hinge Loss 是 VQGAN/Latent Diffusion 的标准配置。当前问题是架构约束不足（缺 SN），而非 loss 函数缺陷。加上 SN
  后仍不稳定再考虑 R3GAN 的 relativistic loss。

  4. SN 替换 BN？

  非常有帮助，甚至是必须的。 BatchNorm 在判别器中引入样本间依赖，无法严格限制 Lipschitz 连续性。SN 对 batch size
  不敏感，计算开销小。

  5. TTUR 适用？

  适用且推荐。 D 跟不上 G 时，提高 D 的学习率让 D 更快适应。

  6. clamp 1e6 是否过大？

  是的。 正常 d_weight 应在 0.1~10 左右。clamp=1e6 等于允许 G 完全忽略重建、只欺骗 D。建议暂时调低到 10.0，等 D
  正常后再放开。

  7. R1 GP 值得尝试？

  值得。 如果 SN 不能完全解决 logits 上升，R1 GP 可以有效控制。

  8. 移除判别器？

  不建议。 LeanVAE 论文自己也用了 PatchGAN。没有判别器只靠 L1/LPIPS 会导致纹理模糊。

---
  总结建议配置

  判别器:  SpectralNorm（移除 BatchNorm）
  学习率:  LR_D = 4~5 × LR_G（TTUR）
  Clamp:  d_weight clamp 调低到 10.0
  可选:    R1 Gradient Penalty (λ~10.0)
  损失:    Hinge Loss（保持不变）